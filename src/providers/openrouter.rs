/// OpenRouter Provider å®ç°æ¨¡å— ğŸŒ
///
/// @è¯ºè¯º çš„ OpenRouter èšåˆå®¢æˆ·ç«¯å®ç°å–µ
///
/// åŠŸèƒ½ï¼š
/// - èšåˆ 22+ LLM æä¾›å•†ï¼ˆOpenAIã€Anthropicã€Groqã€Mistral ç­‰ï¼‰
/// - å…¼å®¹ OpenAI API æ ¼å¼
/// - ç»Ÿä¸€é”™è¯¯å¤„ç†å’Œæ¨¡å‹è·¯ç”±
///
/// ğŸ”’ SAFETY: API Key åŠ å¯†å­˜å‚¨ï¼Œè¯·æ±‚å‚æ•°ä¸¥æ ¼éªŒè¯
///
/// å®ç°è€…: è¯ºè¯º (Nono) âš¡

use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::time::Duration;
use super::openai::{ChatRequest, ChatResponse, Message, ProviderError};

/// ğŸ”’ SAFETY: OpenRouter é…ç½®ç»“æ„ä½“å–µ
#[derive(Debug, Clone)]
pub struct OpenRouterConfig {
    /// ğŸ” PERMISSION: API Keyï¼Œå¿…é¡»é€šè¿‡å®‰å…¨æ¨¡å—åŠ è½½
    pub api_key: String,
    /// API åŸºç¡€ URL
    pub base_url: String,
    /// è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    pub timeout: u64,
    /// æœ€å¤§é‡è¯•æ¬¡æ•°
    pub max_retries: u8,
    /// å…œåº•æ¨¡å‹ï¼ˆå½“æŒ‡å®šæ¨¡å‹ä¸å¯ç”¨æ—¶ï¼‰
    pub fallback_model: String,
}

impl Default for OpenRouterConfig {
    fn default() -> Self {
        Self {
            api_key: String::new(),
            base_url: "https://openrouter.ai/api/v1".to_string(),
            timeout: 30,
            max_retries: 3,
            fallback_model: "openai/gpt-3.5-turbo".to_string(),
        }
    }
}

/// ğŸ”’ SAFETY: OpenRouter æ‰©å±•çš„èŠå¤©è¯·æ±‚ç»“æ„å–µ
/// æ”¯æŒé¢å¤–å‚æ•°å¦‚ provider preferences
#[derive(Debug, Serialize, Clone)]
pub struct OpenRouterRequest {
    /// åŸºç¡€èŠå¤©è¯·æ±‚
    #[serde(flatten)]
    pub base: ChatRequest,
    /// æä¾›å•†åå¥½ï¼ˆå¯é€‰ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub provider: Option<ProviderPreference>,
    /// è·¯ç”±ç­–ç•¥ï¼ˆå¯é€‰ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub route: Option<String>,
    /// å»¶è¿Ÿæ¨¡å¼ï¼ˆå¯é€‰ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub transforms: Option<Vec<String>>,
}

/// ğŸ”’ SAFETY: æä¾›å•†åå¥½ç»“æ„ä½“å–µ
#[derive(Debug, Serialize, Clone)]
pub struct ProviderPreference {
    /// æä¾›å•†æ’åºï¼ˆä¾‹å¦‚ ["openai", "anthropic"]ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub order: Option<Vec<String>>,
    /// å¼ºåˆ¶ä½¿ç”¨ç‰¹å®šæä¾›å•†
    #[serde(skip_serializing_if = "Option::is_none")]
    pub allow: Option<Vec<String>>,
    /// æ’é™¤ç‰¹å®šæä¾›å•†
    #[serde(skip_serializing_if = "Option::is_none")]
    pub deny: Option<Vec<String>>,
}

/// ğŸ”’ SAFETY: OpenRouter æ¨¡å‹ä¿¡æ¯ç»“æ„ä½“å–µ
#[derive(Debug, Deserialize, Clone)]
pub struct ModelInfo {
    /// æ¨¡å‹ ID
    pub id: String,
    /// æ¨¡å‹åç§°
    pub name: String,
    /// æè¿°
    pub description: String,
    /// å®šä»·ä¿¡æ¯
    pub pricing: Pricing,
    /// ä¸Šä¸‹æ–‡é•¿åº¦
    pub context_length: u32,
}

/// ğŸ”’ SAFETY: å®šä»·ä¿¡æ¯ç»“æ„ä½“å–µ
#[derive(Debug, Deserialize, Clone)]
pub struct Pricing {
    /// è¾“å…¥ä»·æ ¼ï¼ˆæ¯ç™¾ä¸‡ tokenï¼Œç¾å…ƒï¼‰
    pub prompt: String,
    /// è¾“å‡ºä»·æ ¼ï¼ˆæ¯ç™¾ä¸‡ tokenï¼Œç¾å…ƒï¼‰
    pub completion: String,
}

/// ğŸ”’ SAFETY: OpenRouter é”™è¯¯ç»“æ„ä½“å–µ
#[derive(Debug, Deserialize)]
pub struct OpenRouterError {
    /// é”™è¯¯è¯¦æƒ…
    pub error: ErrorDetail,
}

/// ğŸ”’ SAFETY: OpenRouter é”™è¯¯è¯¦æƒ…ç»“æ„ä½“å–µ
#[derive(Debug, Deserialize)]
pub struct ErrorDetail {
    /// é”™è¯¯æ¶ˆæ¯
    pub message: String,
    /// é”™è¯¯ç±»å‹
    #[serde(rename = "type")]
    pub error_type: String,
    /// é”™è¯¯ä»£ç 
    pub code: Option<String>,
}

/// ğŸ”’ SAFETY: OpenRouter å®¢æˆ·ç«¯ç»“æ„ä½“å–µ
#[derive(Debug, Clone)]
pub struct OpenRouterClient {
    /// HTTP å®¢æˆ·ç«¯
    client: Client,
    /// é…ç½®
    config: OpenRouterConfig,
}

impl OpenRouterClient {
    /// ğŸ”’ SAFETY: åˆ›å»ºæ–°çš„ OpenRouter å®¢æˆ·ç«¯å–µ
    pub fn new(config: OpenRouterConfig) -> Self {
        let client = Client::builder()
            .timeout(Duration::from_secs(config.timeout))
            .build()
            .unwrap_or_else(|_| Client::new());

        Self { client, config }
    }

    /// ğŸ”’ SAFETY: è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨å–µ
    /// å¼‚æ­¥è°ƒç”¨ OpenRouter çš„ models ç«¯ç‚¹
    pub async fn list_models(&self) -> Result<Vec<ModelInfo>, ProviderError> {
        let url = format!("{}/models", self.config.base_url);

        let response = self.client
            .get(&url)
            .bearer_auth(&self.config.api_key)
            .header("HTTP-Referer", "https://github.com/Gengetau/nekoclaw")
            .header("X-Title", "nekoclaw")
            .send()
            .await?;

        let status = response.status();

        if status.is_success() {
            response.json().await.map_err(ProviderError::from)
        } else {
            let error_text = response.text().await.unwrap_or_default();
            Err(ProviderError::ApiError(format!("HTTP {}: {}", status, error_text)))
        }
    }

    /// ğŸ”’ SAFETY: å‘é€èŠå¤©è¯·æ±‚ï¼ˆå¸¦é‡è¯•å’Œæ¨¡å‹å›é€€ï¼‰å–µ
    async fn send_request_with_retry(&self, request: &OpenRouterRequest) -> Result<ChatResponse, ProviderError> {
        let mut current_request = request.clone();
        let mut last_error = None;

        for attempt in 0..=self.config.max_retries {
            match self.send_request(&current_request).await {
                Ok(response) => return Ok(response),
                Err(e) => {
                    last_error = Some(e);

                    // å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œä¸é‡è¯•
                    if matches!(last_error, Some(ProviderError::AuthError)) {
                        break;
                    }

                    // å¦‚æœå°è¯•å¤±è´¥ä¸”ä¸æ˜¯æœ€åä¸€æ¬¡ï¼Œå°è¯•å›é€€åˆ°å…œåº•æ¨¡å‹
                    if attempt < self.config.max_retries {
                        // æ£€æŸ¥æ˜¯å¦æ˜¯å› ä¸ºæ¨¡å‹ä¸å¯ç”¨å¯¼è‡´çš„é”™è¯¯
                        if let Some(ProviderError::ApiError(msg)) = &last_error {
                            if msg.contains("not available") || msg.contains("not found") {
                                if let Some(model) = current_request.base.model.as_ref() {
                                    if model != &self.config.fallback_model {
                                        // å›é€€åˆ°å…œåº•æ¨¡å‹
                                        current_request.base.model = Some(self.config.fallback_model.clone());
                                        continue;
                                    }
                                }
                            }
                        }

                        // æŒ‡æ•°é€€é¿
                        tokio::time::sleep(Duration::from_millis(100 * (2_u64.pow(attempt as u32)))).await;
                    }
                }
            }
        }

        Err(last_error.unwrap_or_else(|| ProviderError::ApiError("Unknown error".to_string())))
    }

    /// ğŸ”’ SAFETY: å‘é€èŠå¤©è¯·æ±‚ï¼ˆæ ¸å¿ƒå®ç°ï¼‰å–µ
    /// å¼‚å¸¸å¤„ç†: ç½‘ç»œé”™è¯¯ã€è®¤è¯é”™è¯¯ã€æ¨¡å‹ä¸å¯ç”¨é”™è¯¯
    async fn send_request(&self, request: &OpenRouterRequest) -> Result<ChatResponse, ProviderError> {
        let url = format!("{}/chat/completions", self.config.base_url);

        let response = self.client
            .post(&url)
            .bearer_auth(&self.config.api_key)
            .header("Content-Type", "application/json")
            .header("HTTP-Referer", "https://github.com/Gengetau/nekoclaw")
            .header("X-Title", "nekoclaw")
            .json(request)
            .send()
            .await?;

        let status = response.status();

        if status.is_success() {
            response.json().await.map_err(ProviderError::from)
        } else {
            // ğŸ”’ SAFETY: å¤„ç† HTTP é”™è¯¯å“åº”å–µ
            if status.as_u16() == 401 {
                return Err(ProviderError::AuthError);
            }

            let error_text = response.text().await.unwrap_or_default();
            if let Ok(openrouter_error) = serde_json::from_str::<OpenRouterError>(&error_text) {
                Err(ProviderError::ApiError(openrouter_error.error.message))
            } else {
                Err(ProviderError::ApiError(format!("HTTP {}: {}", status, error_text)))
            }
        }
    }
}

/// ğŸ”’ SAFETY: OpenRouter å®¢æˆ·ç«¯å…¬å¼€æ¥å£å–µ
impl OpenRouterClient {
    /// ğŸ”’ SAFETY: èŠå¤©æ¥å£ï¼ˆOpenRouter æ‰©å±•ç‰ˆï¼‰å–µ
    pub async fn chat_api(&self, request: &OpenRouterRequest) -> Result<ChatResponse, ProviderError> {
        self.send_request_with_retry(request).await
    }

    /// ğŸ”’ SAFETY: å…¼å®¹ OpenAI æ¥å£å–µ
    /// å…è®¸æ— ç¼åˆ‡æ¢æä¾›å•†
    pub async fn chat_openai_compatible(&self, request: &ChatRequest) -> Result<ChatResponse, ProviderError> {
        let openrouter_request = OpenRouterRequest {
            base: request.clone(),
            provider: None,
            route: None,
            transforms: None,
        };
        self.chat_api(&openrouter_request).await
    }

    /// ğŸ”’ SAFETY: å¿«æ·æ¥å£å–µ
    /// ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
    pub async fn chat_simple(&self, model: &str, prompt: &str) -> Result<String, ProviderError> {
        let request = OpenRouterRequest {
            base: ChatRequest {
                model: Some(model.to_string()),
                messages: vec![Message::user(prompt.to_string())],
                temperature: None,
                max_tokens: None,
                stream: None,
            },
            provider: None,
            route: None,
            transforms: None,
        };

        let response = self.chat_api(&request).await?;
        Ok(response.choices.get(0)
            .ok_or_else(|| ProviderError::ApiError("No choices in response".to_string()))?
            .message
            .content
            .clone())
    }

    /// ğŸ”’ SAFETY: å¸¦æä¾›å•†åå¥½çš„å¿«æ·æ¥å£å–µ
    pub async fn chat_with_provider(
        &self,
        model: &str,
        prompt: &str,
        preferred_providers: Vec<String>,
    ) -> Result<String, ProviderError> {
        let request = OpenRouterRequest {
            base: ChatRequest {
                model: Some(model.to_string()),
                messages: vec![Message::user(prompt.to_string())],
                temperature: None,
                max_tokens: None,
                stream: None,
            },
            provider: Some(ProviderPreference {
                order: Some(preferred_providers),
                allow: None,
                deny: None,
            }),
            route: None,
            transforms: None,
        };

        let response = self.chat_api(&request).await?;
        Ok(response.choices.get(0)
            .ok_or_else(|| ProviderError::ApiError("No choices in response".to_string()))?
            .message
            .content
            .clone())
    }

    /// ğŸ”’ SAFETY: æ™ºèƒ½æ¨¡å‹é€‰æ‹©å–µ
    /// æ ¹æ®é¢„ç®—å’Œéœ€æ±‚è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ¨¡å‹
    pub async fn get_best_model(&self, budget_usd: f64, context_length: u32) -> Option<ModelInfo> {
        let models = self.list_models().await.ok()?;

        models
            .into_iter()
            .filter(|m| m.context_length >= context_length)
            .min_by(|a, b| {
                // è§£æä»·æ ¼å¹¶æ¯”è¾ƒ
                let a_price: f64 = a.pricing.prompt.parse().unwrap_or(f64::MAX);
                let b_price: f64 = b.pricing.prompt.parse().unwrap_or(f64::MAX);
                a_price.partial_cmp(&b_price).unwrap_or(std::cmp::Ordering::Equal)
            })
            .filter(|m| {
                // æ£€æŸ¥ä»·æ ¼æ˜¯å¦åœ¨é¢„ç®—å†…
                let price: f64 = m.pricing.prompt.parse().unwrap_or(f64::MAX);
                price <= budget_usd
            })
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_config_default() {
        let config = OpenRouterConfig::default();
        assert_eq!(config.base_url, "https://openrouter.ai/api/v1");
        assert_eq!(config.fallback_model, "openai/gpt-3.5-turbo");
    }

    #[test]
    fn test_provider_preference() {
        let pref = ProviderPreference {
            order: Some(vec!["openai".to_string(), "anthropic".to_string()]),
            allow: None,
            deny: None,
        };

        assert!(pref.order.is_some());
        assert_eq!(pref.order.unwrap().len(), 2);
    }
}
