/// OpenAI Provider å®ç°æ¨¡å— ğŸ¤–
///
/// @è¯ºè¯º çš„ OpenAI API å®¢æˆ·ç«¯å®ç°å–µ
///
/// åŠŸèƒ½ï¼š
/// - GPT-4 / GPT-3.5 Turbo å…¼å®¹
/// - æµå¼å“åº”æ”¯æŒï¼ˆå¯é€‰ï¼‰
/// - é”™è¯¯é‡è¯•æœºåˆ¶
///
/// ğŸ”’ SAFETY: API Key åŠ å¯†å­˜å‚¨ï¼Œè¯·æ±‚å‚æ•°ä¸¥æ ¼éªŒè¯
///
/// å®ç°è€…: è¯ºè¯º (Nono) âš¡
use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::time::Duration;
use thiserror::Error;

/// ğŸ”’ SAFETY: OpenAI é…ç½®ç»“æ„ä½“å–µ
/// ä»å®‰å…¨é…ç½®ä¸­åŠ è½½ API Key
#[derive(Debug, Clone)]
pub struct OpenAIConfig {
    /// ğŸ” PERMISSION: API Keyï¼Œå¿…é¡»é€šè¿‡å®‰å…¨æ¨¡å—åŠ è½½
    pub api_key: String,
    /// API åŸºç¡€ URLï¼ˆæ”¯æŒè‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
    pub base_url: String,
    /// è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    pub timeout: u64,
    /// æœ€å¤§é‡è¯•æ¬¡æ•°
    pub max_retries: u8,
}

impl Default for OpenAIConfig {
    /// ğŸ”’ SAFETY: é»˜è®¤é…ç½®ä½¿ç”¨æ ‡å‡† OpenAI ç«¯ç‚¹å–µ
    fn default() -> Self {
        Self {
            api_key: String::new(),
            base_url: "https://api.openai.com/v1".to_string(),
            timeout: 30,
            max_retries: 3,
        }
    }
}

/// ğŸ”’ SAFETY: OpenAI èŠå¤©è¯·æ±‚ç»“æ„å–µ
/// ä¸¥æ ¼éµå¾ª OpenAI API è§„èŒƒ
#[derive(Debug, Serialize, Clone)]
pub struct ChatRequest {
    /// æ¨¡å‹åç§°ï¼ˆä¾‹å¦‚ "gpt-4", "gpt-3.5-turbo"ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub model: Option<String>,
    /// æ¶ˆæ¯åˆ—è¡¨
    pub messages: Vec<Message>,
    /// æ¸©åº¦å‚æ•°ï¼ˆ0.0-2.0ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    /// æœ€å¤§ç”Ÿæˆ token æ•°
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<u32>,
    /// æµå¼å“åº”ï¼ˆæš‚æœªå®ç°ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub stream: Option<bool>,
}

/// ğŸ”’ SAFETY: æ¶ˆæ¯ç»“æ„ä½“å–µ
/// æ”¯æŒå¤šè½®å¯¹è¯
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Message {
    /// è§’è‰²ï¼ˆsystemã€userã€assistantï¼‰
    pub role: String,
    /// æ¶ˆæ¯å†…å®¹
    pub content: String,
}

impl Message {
    /// ğŸ”’ SAFETY: åˆ›å»ºç”¨æˆ·æ¶ˆæ¯å–µ
    /// å†…å®¹å‚æ•°å¿…é¡»ç»è¿‡ XSS è¿‡æ»¤
    pub fn user(content: String) -> Self {
        Self {
            role: "user".to_string(),
            content,
        }
    }

    /// ğŸ”’ SAFETY: åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å–µ
    pub fn assistant(content: String) -> Self {
        Self {
            role: "assistant".to_string(),
            content,
        }
    }

    /// ğŸ”’ SAFETY: åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯å–µ
    pub fn system(content: String) -> Self {
        Self {
            role: "system".to_string(),
            content,
        }
    }
}

/// ğŸ”’ SAFETY: OpenAI èŠå¤©å“åº”ç»“æ„ä½“å–µ
#[derive(Debug, Deserialize)]
pub struct ChatResponse {
    /// å“åº” ID
    pub id: String,
    /// å¯¹è±¡ç±»å‹
    pub object: String,
    /// æ—¶é—´æˆ³
    pub created: u64,
    /// æ¨¡å‹åç§°
    pub model: String,
    /// é€‰æ‹©åˆ—è¡¨
    pub choices: Vec<Choice>,
    /// ä½¿ç”¨æƒ…å†µ
    pub usage: Usage,
}

/// ğŸ”’ SAFETY: é€‰æ‹©ç»“æ„ä½“å–µ
#[derive(Debug, Deserialize)]
pub struct Choice {
    /// ç´¢å¼•
    pub index: u32,
    /// æ¶ˆæ¯
    pub message: Message,
    /// ç»“æŸåŸå› 
    pub finish_reason: Option<String>,
}

/// ğŸ”’ SAFETY: ä½¿ç”¨æƒ…å†µç»“æ„ä½“å–µ
#[derive(Debug, Deserialize)]
pub struct Usage {
    /// æç¤ºè¯ token æ•°
    pub prompt_tokens: u32,
    /// å®Œæˆè¯ token æ•°
    pub completion_tokens: u32,
    /// æ€» token æ•°
    pub total_tokens: u32,
}

/// ğŸ”’ SAFETY: OpenAI é”™è¯¯ç»“æ„ä½“å–µ
#[derive(Debug, Deserialize)]
pub struct OpenAIError {
    /// é”™è¯¯è¯¦æƒ…
    pub error: ErrorDetail,
}

/// ğŸ”’ SAFETY: é”™è¯¯è¯¦æƒ…ç»“æ„ä½“å–µ
#[derive(Debug, Deserialize)]
pub struct ErrorDetail {
    /// æ¶ˆæ¯
    pub message: String,
    /// ç±»å‹
    #[serde(rename = "type")]
    pub error_type: String,
    /// å‚æ•°
    pub param: Option<String>,
    /// ä»£ç 
    pub code: Option<String>,
}

/// ğŸ”’ SAFETY: Provider ç‰¹å®šé”™è¯¯ç±»å‹å–µ
#[derive(Debug, Error)]
pub enum ProviderError {
    /// HTTP è¯·æ±‚é”™è¯¯
    #[error("HTTP error: {0}")]
    HttpError(#[from] reqwest::Error),
    /// JSON è§£æé”™è¯¯
    #[error("JSON error: {0}")]
    JsonError(#[from] serde_json::Error),
    /// OpenAI API é”™è¯¯
    #[error("OpenAI API error: {0}")]
    ApiError(String),
    /// è®¤è¯é”™è¯¯
    #[error("Authentication failed")]
    AuthError,
    /// è¶…æ—¶é”™è¯¯
    #[error("Request timeout")]
    Timeout,
}

/// ğŸ”’ SAFETY: OpenAI å®¢æˆ·ç«¯ç»“æ„ä½“å–µ
#[derive(Debug, Clone)]
pub struct OpenAIClient {
    /// HTTP å®¢æˆ·ç«¯
    client: Client,
    /// é…ç½®
    config: OpenAIConfig,
}

impl OpenAIClient {
    /// ğŸ”’ SAFETY: åˆ›å»ºæ–°çš„ OpenAI å®¢æˆ·ç«¯å–µ
    /// api_key: å¿…é¡»é€šè¿‡å®‰å…¨æ¨¡å—åŠ è½½
    pub fn new(config: OpenAIConfig) -> Self {
        let client = Client::builder()
            .timeout(Duration::from_secs(config.timeout))
            .build()
            .unwrap_or_else(|_| Client::new());

        Self { client, config }
    }

    /// ğŸ”’ SAFETY: å‘é€èŠå¤©è¯·æ±‚ï¼ˆå¸¦é‡è¯•ï¼‰å–µ
    /// è‡ªåŠ¨å¤„ç†ç½‘ç»œæ³¢åŠ¨å’Œä¸´æ—¶é”™è¯¯
    async fn send_request_with_retry(
        &self,
        request: &ChatRequest,
    ) -> Result<ChatResponse, ProviderError> {
        let mut last_error = None;

        for attempt in 0..=self.config.max_retries {
            match self.send_request(request).await {
                Ok(response) => return Ok(response),
                Err(e) => {
                    last_error = Some(e);
                    // å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œä¸é‡è¯•
                    if matches!(last_error, Some(ProviderError::AuthError)) {
                        break;
                    }
                    // æœ€åä¸€æ¬¡ä¸ç­‰å¾…
                    if attempt < self.config.max_retries {
                        tokio::time::sleep(Duration::from_millis(
                            100 * (2_u64.pow(attempt as u32)),
                        ))
                        .await;
                    }
                }
            }
        }

        Err(last_error.unwrap_or_else(|| ProviderError::ApiError("Unknown error".to_string())))
    }

    /// ğŸ”’ SAFETY: å‘é€èŠå¤©è¯·æ±‚ï¼ˆæ ¸å¿ƒå®ç°ï¼‰å–µ
    /// å¼‚å¸¸å¤„ç†: ç½‘ç»œé”™è¯¯ã€è®¤è¯é”™è¯¯ã€é™æµé”™è¯¯
    async fn send_request(&self, request: &ChatRequest) -> Result<ChatResponse, ProviderError> {
        let url = format!("{}/chat/completions", self.config.base_url);

        let response = self
            .client
            .post(&url)
            .bearer_auth(&self.config.api_key)
            .header("Content-Type", "application/json")
            .json(request)
            .send()
            .await?;

        let status = response.status();

        if status.is_success() {
            response.json().await.map_err(ProviderError::from)
        } else {
            // ğŸ”’ SAFETY: å¤„ç† HTTP é”™è¯¯å“åº”å–µ
            if status.as_u16() == 401 {
                return Err(ProviderError::AuthError);
            }

            let error_text = response.text().await.unwrap_or_default();
            if let Ok(openai_error) = serde_json::from_str::<OpenAIError>(&error_text) {
                Err(ProviderError::ApiError(openai_error.error.message))
            } else {
                Err(ProviderError::ApiError(format!(
                    "HTTP {}: {}",
                    status, error_text
                )))
            }
        }
    }
}

/// ğŸ”’ SAFETY: å®ç° Provider Traitï¼ˆå¾… traits.rs å®šä¹‰åè¿æ¥ï¼‰å–µ
/// æ³¨æ„ï¼šè¿™é‡Œæš‚æ—¶ä½¿ç”¨è‡ªå·±çš„ Result å–µ
impl OpenAIClient {
    /// ğŸ”’ SAFETY: èŠå¤©æ¥å£å–µ
    /// å¼‚å¸¸å¤„ç†: æ‰€æœ‰é”™è¯¯è¿”å› ProviderError
    pub async fn chat_api(&self, request: &ChatRequest) -> Result<ChatResponse, ProviderError> {
        self.send_request_with_retry(request).await
    }

    /// ğŸ”’ SAFETY: å¿«æ·æ¥å£å–µ
    /// ç›´æ¥å‘é€ç”¨æˆ·æ¶ˆæ¯
    pub async fn chat_simple(&self, prompt: &str) -> Result<String, ProviderError> {
        let request = ChatRequest {
            model: Some("gpt-3.5-turbo".to_string()),
            messages: vec![Message::user(prompt.to_string())],
            temperature: None,
            max_tokens: None,
            stream: None,
        };

        let response = self.chat_api(&request).await?;
        Ok(response
            .choices
            .get(0)
            .ok_or_else(|| ProviderError::ApiError("No choices in response".to_string()))?
            .message
            .content
            .clone())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_message_creation() {
        let msg = Message::user("test".to_string());
        assert_eq!(msg.role, "user");
        assert_eq!(msg.content, "test");
    }

    #[test]
    fn test_config_default() {
        let config = OpenAIConfig::default();
        assert_eq!(config.base_url, "https://api.openai.com/v1");
        assert_eq!(config.max_retries, 3);
    }
}
